# Лабораторная №1

В этой лабораторной работе я проанализировал датасет [Mobile Price Classification](https://www.kaggle.com/iabhishekofficial/mobile-price-classification). Выявил его недостатки и частично устранил их. С помощью `sklearn.manifold.TSNE` визуализировал данные.

В ходе выполнения были получены навыки работы с `pandas`, `numpy`, `matplotlib`.

Реализовал свои алгоритмы «n-ближайших соседей» и «наивный баесовский классификатор».

## Выводы

В данной лабораторной работе, я разработал instance-based алгоритм. Наивные баесовский классификатор можно отнести к batch learning алгоритмам, т.к. получая новые тренировочные данные, нам нужно заного просчитывать всю модель. knn, в свою очередь, можно отнести к online learning (streaming) алгоритмам, т.к. получая новые тренировочные данные, нам не нужно ничего делать с уже имеющимися.

Качество данных, не менее важно чем качество модели. Исследователь в Microsoft, Мишель Банко и Эрик Брилл показали что разные алгоритмы машинного обучения, показывают почти одинаковые результаты, когда им дают достаточно данных.

Некоторые из проблем с данными:

1. Недостаток данных  
2. Непоказательность (плохая выборка)  
3. Плохое качество: отсутствие данных, погрешность, выбросы  
4. Ненужные характеристики (как следствие - проклятие размерности)  

## Литература

+ Hands-On Machine Learning with Scikit-Learn & TensorFlow  

